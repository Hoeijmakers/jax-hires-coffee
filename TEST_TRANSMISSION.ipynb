{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# We need to import numpyro first, though we use it last\n",
    "import numpyro\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "from numpyro import distributions as dist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate as interp\n",
    "from jax import numpy as jnp\n",
    "from jax import jit\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "    \n",
    "\n",
    "from jax.scipy.optimize import minimize\n",
    "from jax.random import PRNGKey, split\n",
    "\n",
    "import tayph.util as ut\n",
    "import tayph.system_parameters as sp\n",
    "import tayph.functions as fun\n",
    "import tayph.util as ut\n",
    "from tayph.vartests import typetest,notnegativetest,nantest,postest,typetest_array,dimtest\n",
    "from tayph.vartests import lentest\n",
    "import tayph.operations as ops\n",
    "import tayph.masking as masking\n",
    "import copy\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import arviz\n",
    "from corner import corner\n",
    "\n",
    "import astropy.io.fits as fits\n",
    "import astropy.constants as const\n",
    "import astropy.units as u\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "cpu_cores = 4\n",
    "numpyro.set_host_device_count(cpu_cores)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading opacities.\n",
    "Opacity functions of various species are located in the `opacity/` folder. We load them using a binary IO script packaged in `tayph`. We save each species in a species object, and keep track of those with a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class species:#Species\n",
    "  def __init__(self, label, tag):\n",
    "    self.label = label\n",
    "    self.tag = tag\n",
    "    \n",
    "\n",
    "labels = ['Ca', 'Ti', 'V', 'Cr', 'Fe']\n",
    "tags = [2000,2200,2300,2400,2600]\n",
    "\n",
    "labels=['Fe','Ti','V']\n",
    "tags=[2600,2200,2300]\n",
    "S = OrderedDict()#This will hold all my species objects.\n",
    "for i in range(len(labels)):\n",
    "    S[labels[i]] = species(labels[i],tags[i])\n",
    "    \n",
    "    \n",
    "for i in list(S.keys()):\n",
    "    S[i].path = ut.check_path(f'opacity/VALD_{S[i].tag}e2/Out_00000_60000_02500_n800.bin',exists=True)\n",
    "    S[i].kappa = jnp.array(ut.read_binary_kitzmann(S[i].path,double=False))\n",
    "    \n",
    "k_wn = jnp.arange(len(S['Fe'].kappa))*1e-2#Wavenumbers\n",
    "k_wl = 1e7/k_wn#Wavelength in nm; common to all the opacity functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a good choice about what to interpolate this onto, we first load in the data. This is copied out of tayph. It's going to prep our hires data for us. It reads spectral orders and wavelengths from file, and generates uncertainties. We also do velocity correction. This is all data preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = ut.check_path('data/KELT-9/night1/',exists=True)#This follows the file structure of tayph.\n",
    "\n",
    "air = sp.paramget('air',dp)#Whether or not to convert to air wavelengths. Irrelevant for this demo.\n",
    "do_berv_correction = True\n",
    "do_keplerian_correction = True\n",
    "\n",
    "list_of_wls=[]#This will store all the data.\n",
    "list_of_orders=[]#All of it needs to be loaded into your memory, more than once.\n",
    "list_of_sigmas=[]#Hope that's ok...\n",
    "n_negative_total = 0#This will hold the total number of pixels that were set to NaN because\n",
    "\n",
    "filelist_orders= [str(i) for i in Path(dp).glob('order_*.fits')]\n",
    "if len(filelist_orders) == 0:#If no order FITS files are found:\n",
    "    raise Exception(f'Runtime error: No orders_*.fits files were found in {dp}.')\n",
    "try:\n",
    "    order_numbers = [int(i.split('order_')[1].split('.')[0]) for i in filelist_orders]\n",
    "except:\n",
    "    raise Exception('Runtime error: Failed at casting fits filename numerals to ints. Are the '\n",
    "    'filenames of all of the spectral orders correctly formatted (e.g. order_5.fits)?')\n",
    "order_numbers.sort()#This is the ordered list of numerical order IDs.\n",
    "n_orders = len(order_numbers)\n",
    "\n",
    "\n",
    "for i in order_numbers:\n",
    "    wavepath = dp/f'wave_{i}.fits'\n",
    "    orderpath= dp/f'order_{i}.fits'\n",
    "    ut.check_path(wavepath,exists=True)\n",
    "    ut.check_path(orderpath,exists=True)\n",
    "    wave_order = ut.readfits(wavepath)#2D or 1D?\n",
    "    order_i = ut.readfits(orderpath)\n",
    "\n",
    "    #Check dimensionality of wave axis and order. Either 2D or 1D.\n",
    "    if wave_order.ndim == 2:\n",
    "\n",
    "        n_px = np.shape(wave_order)[1]#Pixel width of the spectral order.\n",
    "        dimtest(wave_order,np.shape(order_i),'wave_order in tayph.run_instance()')\n",
    "    elif wave_order.ndim == 1:\n",
    "        n_px = len(wave_order)\n",
    "        dimtest(order_i,[0,n_px],f'order {i} in run_instance()')\n",
    "    else:\n",
    "        raise Exception(f'Wavelength axis of order {i} is neither 1D nor 2D.')\n",
    "\n",
    "    if i == np.min(order_numbers):\n",
    "        n_exp = np.shape(order_i)[0]#For the first order, we fix n_exp.\n",
    "    else:\n",
    "        dimtest(order_i,[n_exp,n_px],f'order {i} in run_instance()')\n",
    "\n",
    "    #Deal with air or vaccuum wavelengths:\n",
    "    if air == False:\n",
    "        list_of_wls.append(copy.deepcopy(wave_order))\n",
    "    else:\n",
    "        list_of_wls.append(ops.airtovac(wave_order))\n",
    "\n",
    "\n",
    "    #Now test for negatives, set them to NaN and track them.\n",
    "    n_negative = len(order_i[order_i <= 0])\n",
    "    n_negative_total+=n_negative\n",
    "    order_i[order_i <= 0] = np.nan #This is very important for later when we are computing\n",
    "    #average spectra and the like, to avoid divide-by-zero cases.\n",
    "    postest(order_i,f'order {i} in run_instance().')#make sure whatever comes out here is\n",
    "    #strictly positive.\n",
    "    list_of_orders.append(order_i)\n",
    "    list_of_sigmas.append(np.sqrt(order_i))\n",
    "\n",
    "    \n",
    "oi = 6 #This is the order that's going to be plotted below.\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.imshow(list_of_orders[oi],aspect='auto')\n",
    "plt.title(f'Order # {oi}')\n",
    "plt.xlabel('Px')\n",
    "plt.ylabel('Exp')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rv_cor = 0#This initialises as an int. If any of the following is true, it becomes a float.\n",
    "if do_berv_correction:\n",
    "    rv_cor += sp.berv(dp)\n",
    "if do_keplerian_correction:\n",
    "    rv_cor-=sp.RV_star(dp)*(1.0)\n",
    "\n",
    "gamma = 1.0+(rv_cor*u.km/u.s/const.c)#Doppler factor.\n",
    "\n",
    "\n",
    "list_of_orders_cor = []\n",
    "list_of_sigmas_cor = []\n",
    "list_of_wls_cor = []\n",
    "\n",
    "for i in range(len(list_of_wls)):\n",
    "    order = list_of_orders[i]\n",
    "    sigma = list_of_sigmas[i]\n",
    "    order_cor = order*0.0\n",
    "    sigma_cor = sigma*0.0\n",
    "    if list_of_wls[i].ndim==2:\n",
    "        wl_cor = list_of_wls[i][0]#Interpolate onto the 1st wavelength axis of the series if 2D.\n",
    "    elif list_of_wls[i].ndim==1:\n",
    "        wl_cor = list_of_wls[i]\n",
    "    else:\n",
    "        raise Exception(f'Wavelength axis of order {i} is neither 1D nor 2D.')\n",
    "\n",
    "    for j in range(len(list_of_orders[0])):\n",
    "        if list_of_wls[i].ndim==2:\n",
    "            if type(rv_cor) != int:#If wl 2D and rv_cor is non-zero:\n",
    "                order_cor[j] = interp.interp1d(list_of_wls[i][j]*gamma[j],order[j],bounds_error=False)(wl_cor)\n",
    "                sigma_cor[j] = interp.interp1d(list_of_wls[i][j]*gamma[j],sigma[j],bounds_error=False)(wl_cor)#I checked that this works because it doesn't affect\n",
    "                #the SNR, apart from wavelength-shifting it.\n",
    "            else:#If wl is 2D and rv_cor is not populated, there is no multiplication with gamma\n",
    "                order_cor[j] = interp.interp1d(list_of_wls[i][j],order[j],bounds_error=False)(wl_cor)\n",
    "                sigma_cor[j] = interp.interp1d(list_of_wls[i][j],sigma[j],bounds_error=False)(wl_cor)\n",
    "        else:\n",
    "            if type(rv_cor) != int:#If wl 1D and rv_cor is non-zero:\n",
    "                order_cor[j] = interp.interp1d(list_of_wls[i]*gamma[j],order[j],bounds_error=False)(wl_cor)\n",
    "                sigma_cor[j] = interp.interp1d(list_of_wls[i]*gamma[j],sigma[j],bounds_error=False)(wl_cor)\n",
    "            else:\n",
    "                #No interpolation at all:\n",
    "                order_cor[j]=order[j]\n",
    "                sigma_cor[j]=sigma[j]\n",
    "\n",
    "    list_of_orders_cor.append(order_cor)\n",
    "    list_of_sigmas_cor.append(sigma_cor)\n",
    "    list_of_wls_cor.append(wl_cor)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_start = 0\n",
    "order_end = 10\n",
    "\n",
    "min_wl = np.inf\n",
    "max_wl = 0\n",
    "\n",
    "\n",
    "mask = sp.transit(dp)\n",
    "mask[mask<1]=0\n",
    "\n",
    "list_of_orders_oot = []\n",
    "list_of_wls_oot = []\n",
    "list_of_sigmas_oot = []\n",
    "for i in range(order_start,np.min([order_end,len(list_of_orders)])):\n",
    "    list_of_orders_oot.append(list_of_orders_cor[i][mask==1])\n",
    "    list_of_wls_oot.append(list_of_wls_cor[i])\n",
    "    list_of_sigmas_oot.append(list_of_sigmas_cor[i][mask==1])\n",
    "    min_wl = np.min([np.min(list_of_wls_cor[i]),min_wl])\n",
    "    max_wl = np.max([np.max(list_of_wls_cor[i]),max_wl])\n",
    "        \n",
    "list_of_wld = copy.deepcopy(list_of_wls_oot)\n",
    "        \n",
    "plt.figure(figsize=(14,5))\n",
    "plt.imshow(list_of_orders_oot[oi],aspect='auto')\n",
    "plt.title(f'Order # {oi} with in-transit data rejected')\n",
    "plt.xlabel('Px')\n",
    "plt.ylabel('Exp')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "n_exp = len(list_of_orders_oot[0])\n",
    "phase = np.linspace(-0.05,0.05,n_exp)#This will be used later to shift the model.\n",
    "\n",
    "print(min_wl,max_wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "meanfluxes = []#These are the time-dependent average fluxes that we divide out of each order.\n",
    "meanspecs = []#These are the average spectra that we divide out of each order.\n",
    "list_of_res = []\n",
    "list_of_res_e = []\n",
    "\n",
    "for i in range(len(list_of_orders_oot)):\n",
    "    order = list_of_orders_oot[i]\n",
    "    sigma = list_of_sigmas_oot[i]\n",
    "    meanflux = np.nanmean(order,axis=1)\n",
    "    meanfluxes.append(meanflux)\n",
    "    order_norm = (order.T/meanflux).T\n",
    "    sigma_norm = (sigma.T/meanflux).T\n",
    "    meanspec = np.nanmean(order_norm,axis=0)\n",
    "    meanspecs.append(meanspec)\n",
    "    \n",
    "    order_clean = order_norm/meanspec\n",
    "    sigma_clean = sigma_norm/meanspec\n",
    "    \n",
    "    #I'm also going to set NaNs to 1.0 and then set sigma to infinite there.\n",
    "    sigma_clean[np.isfinite(order_clean)==False]=np.inf\n",
    "    order_clean[np.isfinite(order_clean)==False]=1.0\n",
    "    \n",
    "    list_of_res.append(order_clean)\n",
    "    list_of_res_e.append(sigma_clean)\n",
    "    \n",
    "stdev = np.nanmedian(list_of_res_e[oi])    \n",
    "\n",
    "    \n",
    "plt.figure(figsize=(14,5))\n",
    "plt.imshow(list_of_res[oi],aspect='auto',vmin=1-3*stdev,vmax=1+3*stdev)\n",
    "plt.title(f'Normalised order # {oi}')\n",
    "plt.ylabel('Exp')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    \n",
    "plt.figure(figsize=(14,5))\n",
    "plt.imshow(list_of_res_e[oi],aspect='auto')\n",
    "plt.title(f'Normalised uncertainties of order # {oi}')\n",
    "plt.xlabel('Px')\n",
    "plt.ylabel('Exp')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "expfit = 11\n",
    "xfit = np.arange(len(list_of_res[oi][expfit]))\n",
    "fit = np.polyfit(xfit, list_of_res[oi][expfit], 1,w = 1/list_of_res_e[oi][expfit])\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(xfit,list_of_res[oi][expfit])\n",
    "plt.plot(xfit,np.poly1d(fit)(xfit))   \n",
    "plt.title('Fitting residuals with a 1st-order polynomial seems like a good idea')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_filters = []\n",
    "list_of_res_clean = []\n",
    "list_of_res_clean_e = []\n",
    "deg = 1\n",
    "for i in range(len(list_of_res)):\n",
    "    order = list_of_res[i]\n",
    "    xfit = np.arange(len(order[0]))\n",
    "    polyfilter = order*0.0\n",
    "    fit2d = np.polyfit(xfit,order.T,deg).T\n",
    "\n",
    "    for j in range(len(order)):\n",
    "        polyfilter[j] = np.poly1d(fit2d[j])(xfit)\n",
    "    list_of_filters.append(polyfilter) \n",
    "    list_of_res_clean.append(list_of_res[i]/polyfilter)\n",
    "    list_of_res_clean_e.append(list_of_res_e[i]/polyfilter)\n",
    "        \n",
    "stdev = np.nanmedian(list_of_res_e[oi])\n",
    "# plt.figure(figsize=(14,5))\n",
    "# plt.imshow(list_of_res[oi],aspect='auto',vmin=1-3*stdev,vmax=1+3*stdev)\n",
    "# plt.title(f'Normalised order # {oi} before colour-detrending')\n",
    "# plt.ylabel('Exp')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.imshow(list_of_filters[oi],aspect='auto',vmin=1-3*stdev,vmax=1+3*stdev)\n",
    "plt.title(f'The filter applied to order # {oi}')\n",
    "plt.ylabel('Exp')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.imshow(list_of_res[oi]/list_of_filters[oi],aspect='auto',vmin=1-3*stdev,vmax=1+3*stdev)\n",
    "plt.title(f'Normalised order # {oi} after colour-detrending')\n",
    "plt.ylabel('Exp')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fxd = np.hstack(list_of_res_clean) #This is the data.\n",
    "err = np.hstack(list_of_res_clean_e)#This is the uncertainty\n",
    "fxf = np.hstack(list_of_filters)#This is the filter\n",
    "wld = np.hstack(list_of_wld)#This is the wavelength axis.\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.imshow(fxd,aspect='auto',vmin=1-3*stdev,vmax=1+3*stdev)\n",
    "plt.title(f'All the renormalised, cleaned data')\n",
    "plt.ylabel('Exp')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.imshow(fxf,aspect='auto',vmin=1-3*stdev,vmax=1+3*stdev)\n",
    "plt.title(f'The filter that will be passed to the model.')\n",
    "plt.ylabel('Exp')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "Now we have the data, with wavelengths, we can go back to the opacities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are going to bracket the minimum and maximum wavelengths of the intermediate wavelength array by 500 km/s in velocity.\n",
    "doppler_factor = (500*u.km/u.s / const.c).decompose().value\n",
    "min_wl*=(1-doppler_factor)\n",
    "max_wl*=(1+doppler_factor)\n",
    "\n",
    "\n",
    "for i in list(S.keys()):\n",
    "    wli,kappa_i,dv = ops.constant_velocity_wl_grid(np.array(k_wl[1:]),np.array(S[i].kappa[1:]),\n",
    "                                                       oversampling=1.0,minmax=[min_wl,max_wl]) # The intermediate wavelength grid.\n",
    "                                                        #Index it from 1 onwards because the first value is np.inf.\n",
    "#     S[i].kappa_i = jnp.array(kappa_i)\n",
    "    S[i].kappa_i = copy.deepcopy(kappa_i)\n",
    "    \n",
    "    \n",
    "    \n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "for i in list(S.keys()):\n",
    "    plt.plot(wli,S[i].kappa_i,label=i,linewidth=0.5,alpha=0.7)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Wavelength (nm)')\n",
    "plt.title(\"Opacity functions of various species on our wavelength range\")\n",
    "plt.ylabel('Opacity (cm$^2$g$^{-1}$)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining the planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.57721\n",
    "RJ = const.R_jup.cgs.value\n",
    "MJ = const.M_jup.cgs.value\n",
    "G = const.G.cgs.value\n",
    "Rsun = const.R_sun.cgs.value\n",
    "\n",
    "P0 = (1.0*u.bar).cgs.value#bar\n",
    "R0 = 1.8*RJ\n",
    "M0 = 1.2*MJ\n",
    "k = const.k_B.cgs.value\n",
    "m = 2.33*const.u.cgs.value\n",
    "Rs = 1.4*Rsun\n",
    "g = G*M0 / R0**2\n",
    "c = const.c.to('km/s').value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare all the inputs for the jax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwli = len(wli)\n",
    "nwld = len(wld)\n",
    "nexp = len(fxf)\n",
    "wld_b = wld.tobytes()\n",
    "\n",
    "kappa_grid = np.vstack([S['Fe'].kappa_i,S['Ti'].kappa_i,S['V'].kappa_i])\n",
    "n_species = len(kappa_grid)#The first species should be Fe.\n",
    "kappa_grid_b = kappa_grid.tobytes()\n",
    "fxf_b = fxf.tobytes()\n",
    "wli_b = wli.tobytes() #This is used later than the others; when the spectrum needs to be shifted & interpolated.\n",
    "phase_b = phase.tobytes()\n",
    "\n",
    "sfwhm = 2*np.sqrt(2*np.log(2))#2.355...\n",
    "\n",
    "\n",
    "#We calculate what range we want for the convolution kernel.\n",
    "mf=5.0#max_fwhm_expected\n",
    "nf=4.0#How many times wider the kernel is compared to the fwhm of the lsf?\n",
    "k_size = int(mf/dv*nf)\n",
    "if k_size%2 == 0: k_size+=1#Make sure that it is odd.\n",
    "x_kernel = (np.arange(k_size)-(k_size-1)/2)*dv #This places 0 directly in the middle; and serves as the x axis of our convolution. On-the-fly, this will be used to calculate a gaussian with which to convolve.\n",
    "x_kernel_b = x_kernel.tobytes()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a down-scoped version of the model. \n",
    "This has no 2D-ness at the moment. Orbital phases are passed but ignored. The only velocities are the linewidth and the v_sys (shfit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jit, static_argnums=(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17))\n",
    "def model_downscoped_jax(p,wl_B,wlk_B,kappa_grid_B,x_kernel_B,phase_B,c,gamma,k,m,g,P0,R0,Rs2,nwli,nwld,nexp,n_species):\n",
    "    #This version takes only a single spectrum. No convolution is done. Kp is not used. Only vsys.\n",
    "    #lw is not passed. kernel is not passed. phase is not passed. No filtering is done.\n",
    "    wl = np.frombuffer(wl_B)\n",
    "    wlk = np.frombuffer(wlk_B)#The wavelengths of the opacity grid.\n",
    "    kappa_grid = np.reshape(np.frombuffer(kappa_grid_B),(n_species,nwli))\n",
    "#     filters = np.reshape(np.frombuffer(filters_B),(nexp,nwld))\n",
    "    x_kernel = np.frombuffer(x_kernel_B)\n",
    "    phase = np.frombuffer(phase_B)\n",
    "    \n",
    "    \n",
    "    T = p[0]\n",
    "    chi_fe = 10**p[1]\n",
    "    logratios = jnp.array(p[2:n_species+1]) #Add a zero for Fe itself. Is this going to mess up autodif?\n",
    "    logk0 = p[n_species+1]\n",
    "    c0 = p[n_species+2] #Constant offset to ensure continuum-degeneracy despite filtering. \n",
    "    lw = p[n_species+3]\n",
    "    vsys = p[n_species+4]\n",
    "#     Kp = p[n_species+5]\n",
    "\n",
    "    \n",
    "    #Then we compute kappa:\n",
    "    chi_i = chi_fe * 10 ** logratios \n",
    "    K = chi_fe * kappa_grid[0] + jnp.dot(chi_i,kappa_grid[1:]) + 10**logk0\n",
    "    \n",
    "    #Then we do the magic:\n",
    "    H = k*T/m/g\n",
    "    R = R0 + H*(gamma+jnp.log(P0 * K / g * jnp.sqrt(2*np.pi*R0/H) ) )*20\n",
    "    RT = c0-R**2 / Rs**2\n",
    "    \n",
    "    #Then we convolve:\n",
    "    kernel = jnp.exp(-0.5 * x_kernel**2 / lw**2)\n",
    "    RT_b = jnp.convolve(RT,kernel/jnp.sum(kernel),mode='same')\n",
    "    \n",
    "    #Then we populate the 2D time series:\n",
    "#     rvp = jnp.sin(phase*2*np.pi)*Kp + vsys #Radial velocity of the planet as a function of the orbital phase.\n",
    "    \n",
    "#     rvp=vsys\n",
    "#     shifted_wl = jnp.outer(1-rvp/c,wl)#This populates a 2D matrix containing a row of shifted wavelengths for each of the spectra.\n",
    "    shifted_wl = (1-vsys/c) * wl\n",
    "    spec = jnp.interp(shifted_wl,wlk,RT_b)\n",
    "#     spec2D = jnp.interp(shifted_wl,wlk,RT_b)\n",
    "    return(spec)\n",
    "#     return ((spec2D.T/jnp.mean(spec2D,axis=1)).T*filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_p = [2500.0,-4.0,-1.0,-1.0,-1.0,1.0,8.0/sfwhm,20.0]\n",
    "\n",
    "phases_b = np.array([-0.05,0.05]).tobytes()\n",
    "true_downscoped_model = model_downscoped_jax(true_p,wld_b,wli_b,kappa_grid_b,x_kernel_b,phases_b,c,gamma,k,m,g,P0,R0,Rs**2,nwli,nwld,nexp,n_species)\n",
    "\n",
    "\n",
    "# DATA = true_downscoped_model + np.random.normal(loc=0.0,scale=0.01,size=(2,len(wld)))\n",
    "DATA = true_downscoped_model + np.random.normal(loc=0.0,scale=0.01,size=len(wld))\n",
    "DATA_E = DATA*0.0+0.01\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(wld,DATA)\n",
    "plt.plot(wld,true_downscoped_model)\n",
    "plt.ylim(0.7,1.1)\n",
    "plt.title('This is what the model and data look like. Straight lines cutting through come from order overlaps. Nothing to worry about.')\n",
    "plt.xlim(390,391)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpyro_model():\n",
    "    \"\"\"\n",
    "    Define a model to sample with the No U-Turn Sampler (NUTS) via numpyro.\n",
    "    \n",
    "    The two Gaussians are defined by an amplitude, mean, and standard deviation.\n",
    "    \n",
    "    To find unique solutions for the two Gaussians, we put non-overlapping bounded \n",
    "    priors on the two amplitudes, but vary the means and stddev's with identical \n",
    "    uniform priors. \n",
    "    \"\"\"\n",
    "    # Define a prior for the temperature:\n",
    "    T_prior = numpyro.sample('T', dist.Uniform(low=2200, high=2800))\n",
    "    \n",
    "    # Uniform prior for log(chi_fe)\n",
    "    chi_fe_prior = numpyro.sample(\n",
    "        'log($\\chi_{Fe}$)', dist.Uniform(low=-4.5, high=-3.5))\n",
    " \n",
    "    chi_ratio_priors = []\n",
    "    for i in range(1,len(labels)):\n",
    "        chi_ratio_priors.append(numpyro.sample('log($\\chi_{'+labels[i]+'}$ / $\\chi_{Fe}$)', dist.Uniform(low=-1.5, high=-0.5)))\n",
    "        \n",
    "\n",
    "    \n",
    "    # Uniform prior for log(k0):\n",
    "    k0_prior = numpyro.sample('log($\\kappa_0$)', dist.Uniform(low=-1.5, high=-0.5))\n",
    "\n",
    "#     Uniform prior for log(k0):\n",
    "#     c_prior = numpyro.sample('c', dist.Normal(loc=1.0, scale=0.001))\n",
    "    c_prior = numpyro.sample('c0', dist.Uniform(low=0.96, high=1.04))\n",
    "    \n",
    "    lw_prior = numpyro.sample('lw', dist.Uniform(low=5/sfwhm, high=15/sfwhm))\n",
    "    vsys_prior = numpyro.sample('$v_{sys}$', dist.Uniform(low=17, high=23))\n",
    "#     Kp_prior = numpyro.sample('$K_p$', dist.Uniform(low=130, high=170))\n",
    "    \n",
    "#     priors = [T_prior,chi_fe_prior]+chi_ratio_priors+[k0_prior,c_prior,lw_prior,vsys_prior,Kp_prior]\n",
    "    priors = [T_prior,chi_fe_prior]+chi_ratio_priors+[k0_prior,c_prior,lw_prior,vsys_prior]\n",
    "    \n",
    "    # Normally distributed likelihood\n",
    "    numpyro.sample(\"obs\", dist.Normal(loc=model_downscoped_jax(priors,wld_b,wli_b,kappa_grid_b,\n",
    "                                                       x_kernel_b,phases_b,c,gamma,k,m,g,P0,R0,\n",
    "                                                       Rs**2,nwli,nwld,nexp,n_species),\n",
    "                                      scale=DATA_E), obs=DATA)\n",
    "\n",
    "    \n",
    "from jax.random import PRNGKey, split\n",
    "import arviz\n",
    "from corner import corner\n",
    "rng_seed = 42\n",
    "rng_keys = split(PRNGKey(rng_seed),cpu_cores\n",
    ")\n",
    "\n",
    "# Define a sampler, using here the No U-Turn Sampler (NUTS)\n",
    "# with a dense mass matrix:\n",
    "sampler = NUTS(\n",
    "    numpyro_model, \n",
    "    dense_mass=True\n",
    ")\n",
    "\n",
    "# Monte Carlo sampling for a number of steps and parallel chains: \n",
    "mcmc = MCMC(\n",
    "    sampler, \n",
    "    num_warmup=15, \n",
    "    num_samples=45, \n",
    "    num_chains=4\n",
    ")\n",
    "\n",
    "# Run the MCMC\n",
    "mcmc.run(rng_keys)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = arviz.from_numpyro(mcmc)\n",
    "\n",
    "# these are the inputs to the synthetic double-gaussian profile (blue lines)\n",
    "truths = {'T': true_p[0], \n",
    "          'log($\\chi_{Fe}$)': true_p[1], \n",
    "          'log($\\chi_{Ti}$ / $\\chi_{Fe}$)' : true_p[2],\n",
    "          'log($\\chi_{V}$ / $\\chi_{Fe}$)' : true_p[3],\n",
    "          'log($\\kappa_0$)': true_p[4], \n",
    "          'c0': true_p[5],\n",
    "          'lw': true_p[6],\n",
    "          '$v_{sys}$': true_p[7]\n",
    "         }\n",
    "\n",
    "# lw_prior = numpyro.sample('lw', dist.Uniform(low=3/sfwhm, high=20/sfwhm))\n",
    "# vsys_prior = numpyro.sample('$v_{sys}$', dist.Uniform(low=10, high=30))\n",
    "# Kp_prior = numpyro.sample('$K_p$', dist.Uniform(low=130, high=170))\n",
    "# make a corner plot\n",
    "corner(\n",
    "    result, \n",
    "    quiet=True, \n",
    "    truths=truths\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
